
# Metagenomics benchmark

### Legend

The commands executed to obtain results from the tools are listed in the file data/all_commands.txt

data/database_sequences.txt contains list of sequence ids of all the sequence genomes in the database.

The results are shown for each dataset where every dataset has its order number.
The numbers for each dataset:

- 1 - 01_Mock_100000-bacteria-l1000-q10.fastq
- 2 - 02_silico-30p-human-70p-bac.fastq
- 3 - 03_silico-10-bacteria-100k-reads.fasta
- 4 - 04_silico-3-euka-bac-100k-reads.fastq
- 5 - 05_human-pathogen.fastq
- 6 - 06_50-bac-100k.fastq
- 8 - 08_negative2_10bac_shuffled_human_20k.fasta
- 9 - 09_zymo_pacbio.fastq
- 10 - 10_zymo_ont.fastq
- 11 - 11_SRR11606871_subsampled.fastq

Database have these names:
 - custom - database built from refseq Bacteria and Archaea genomes
 - human - same database as custom + human genome

extension:
 - .stat - file extension for classification results obtained after processing of classificators results
 	- each row in the .stat file is in format: <is_classified>	<read_id>	<tax_id>	<length>	<percentage>
 	- <is_classified> - C for classified read_id, U for unclassified
 	- <read_id> - id of the classified read
 	- <tax_id> - tax id of the clade to which the read is classified
 	- <length> - length of the read if accessible
 	- <percentage> - some tools classify reads to more than one tax is, if so those reads are classified in <percentage> to certain tax ids. 
 - .f2 - file extension for cleaned classification results obtained after processing .stat files. All rows contain only classified reads.
 	- each row in the .f2 file is in format: <read_id>	<tax_id>	<percentage>	<level>
 	- <level> - taxon level: species, genus, family...
 - .report - report file, every row contains number of reads classified to a taxon: <tax_id>	<species_name>	<true_number>	<kraken_number>	<centrifuge_number>	<clark_number>	<metamaps_number>	<megan_number>	<>
 - .report_truth - report file, same as .report, but with only true positive results
 - .ab - abundance report file, every row contains relative abundance 

### Supporting files:

Download the supporting files from the following link: 
https://zenodo.org/deposit/5151469

The supporting files contain:

1. abundances_reports - abundances report files of for every dataset
2. cleaned_results - results of the classification after the parsing of .stat files, stored in .f2 format for species level
3. cleaned_results_genus - results of the classification after the parsing of .stat files, stored in .f2 format for genus level
nodes.dmp and names.dmp taxonomy files
4. reports - complete read count results for species level stored in .report format, true positive read counts results for species level stored in .report format
reports_genus - complete read count results for genus level stored in .report format, true positive read counts results for genus level stored in .report format
5. results - results of the classifications for every tool whose results need preprocessing: kraken, clark, clark-s, metamaps, megan and centrifuge
6. true_negatives - number of true negative read counts for species level 
7. true_negatives_genus - number of true negative read counts for species level 
8. truth - ground truth for species level in .f2 format
9. truth_genus - ground truth for genus level in .f2 format
	
abundances_reports, cleaned_results, cleaned_results_genus, reports, true_negatives and true_negatives_genus can be regenerated by running the corresponding scripts from the root folder.

Along with the supporting files, scripts use already uploaded files in the data folder:

1. genome_database_sizes.txt - average lengths of genomes obtained from the NCBI web page.
2. missing_genus.txt and missing_species.txt - species that are in the datasets but are not present in the database.

In order to execute the analysis, extract the supporting file archive into the root directory of this project.

### Scripts:
 
 - **parse_tool_output.py** - parses classification output files from tools and produces read_id to tax_id mappings in .stat file
 	- arguments: <tool> <results_path> <fileout>
 		- <tool> name of the tool, kraken, clark, clark-s, centrifuge, metamaps or megan
 		- <results_path> path to the classification results file
 		- <fileout> path to the resulting .stat file

- **analize_tool_output.py** - takes .stat file and produces .f2 file
	- arguments: <tool> <results_path> <nodes_file> <fileout> <target_rank>
		- <tool> name of the tool
		- <results_path> .stat file
		- <nodes_file> path to the nodes.dmp file
		- <fileout> path to the resulting .f2 file
		- <target_rank> species or genus

- **analize_results.py** - analizes .f2 results from all the tools for one dataset and one database and generates .report file
	- arguments: <root_cleaned> <root_reports> <dataset> <database> <names_file> <truth_path> <target_rank>
		- <root_cleaned> - path to the root folder that contains .f2 files
		- <root_reports> - path to the root folder where the reports are stored
		- <dataset> - name of the dataset
		- <database> - name of the database
		- <names_file> - path to the names.dmp file
		- <truth_path> - path to the truth directory
		- <target_rank> - species or genus

- **analize_true_positives.py** - similar to analize_results.py but it only calculates true positive report. The input argumates are the same as for the analize_results.py.

- **benchmark.py** - script that executes whole analysis pipeline, for every tool it executes parse_tool_output, then analize_tool_output and then for every dataset and database it generates reports with analize_results
	- arguments: <mode> there are 4 modes in which this script can be run:
		- only_parsing - only parse_tool_output is executed for every tool, database and dataset, .stat files are generated
		- only_cleaning - only analize_tool_output is executed for evey tool, database and dataset, .f2 files are generated, but the precondition is that .stat files have been generated in advance
		- clean_and_parse - parse_tool_output and analize_tool_output are executed without generating reports
		- only_reports - only .report files are generated, but the precondition is that .f2 files were generated in advance
		- all - all the steps are executed and resulting .report files are generated for evey tool, dataset and database
	- in order to execute analysis for genus level uncoment the commented lines in the script

- **analize_abundances.py** - script that prints the .report file containing analysis of abundances for one dataset and one database. It generates .report file but with abundance estimations for species. The abundance of the species is calculated as the total sum of the reads classified to that species, divided by the average length of the genome of that species.
	- arguments: <dataset> <database> <genome_sizes_filename> <path_to_dataset> <root_cleanded> <root_abundances> <names_file> <dataset_format>
		- <dataset> - name of the dataset
		- <database> - name of the database
		- <genome_sizes_filename> - path to the file that contains the lengths of genomes
		- <path_to_dataset> - path to the reads
		- <root_cleanded> - path to the root folder that contains .f2 files
		- <root_abundances> - path to the root folder where the abundance reports are stored
		- <names_file> - path to the names.dmp file
		- <dataset_format> - format of the dataset, fastq or fasta

- **abundances.py** - script that calculates all the abundance reports for all the datasets and databases.
	- arguments: <genome_sizes_filename> <path_to_datasets>
		- <genome_sizes_filename> - path to the file that contains the lengths of genomes
		- <path_to_datasets> - path to where the all the datasets are stored
	- in order to execute analysis for only portion of longest reads uncomen the commented lines in the script

- **analize_true_negative.py** - script that calculates true negatives for datasets 1-6 and false negatives for dataset 8. The results are outputed in the format where in each row there are three values separated by tab. First value is the number of true negative reads that are in the ground truth (so without shuffle reads), second value is the number of false negative reads that are not in the ground truth (zero for all datasets excpet dataset 8). 

- **paf_to_f2.py (sam_to_f2.py)** - script that parses .paf (.sam) files and extracts read classifications in the .f2 format. 
	- arguments: <path_to_paf(sam)_file> <output_file> <nodes_file> <target_rank>
		- <path_to_paf(sam)_file> - results file in paf (sam) format
		- <output_file> - output file in f2 format 
		- <nodes_file> - nodes file
		- <target_rank> - species or genus


